\section{System}\label{sec:System}
\todo[inline, color=yellow]{Laura}
The actual application can be divided into to type of VR rooms. First of all there is a learning room, where the user can get in touch with the different interaction methods and afterwards different tasks will be presented to him in a VR supermarket scenario (compare section~\ref{sec:VRLabor}). In the learning room the user will be supported in his learning process by a selfteaching system (compare section~\ref{sec:selfteaching}), which can get switched on and off, when he is in the supermarket. The user can make this setting among all other settings in a Menu  (compare section~\ref{sec:Menu}), which is controllable with the \textit{HTC Vive}-controller. 

\subsection{VR Labor}\label{sec:VRLabor}
\todo[inline, color=red]{Anna}

\subsubsection{Learningroom}
\subsubsection{Supermarket}

\subsection{Controller Menu} \label{sec:Menu}
\todo[inline, color=red]{Anna}

\subsection{Interaction Methods}\label{sec:Interactions}
\todo[inline, color=yellow]{Laura}
Of course there were various different interaction methods required to make the \textit{Interaction Lab} suitable for the testing described and evaluated in section~\ref{sec:evaluation}. Also all interaction methods are implemented to realise the grabbing of virtual objects, there can be separated in the two categories, described in the next two paragraphs:

\paragraph{Close Range (CR) Interactions:} The CR can be interpreted as a synonym for the natural interaction radius of the person. Due to this definition it is excluded that those interactions can be used outside an area, which the person can not reach with his arm, or to be more precise: with the controller in his hand. In other words: the CR combines all interactions which can be used to pick up objects in the direct reach of the user.

\paragraph{Far Range (FR) Interactions:} Due to a limitation of the range of motion in VR applications, it is common to have grabbing interactions, which allow the users to grab objects which are normally seen as out of their reach~\cite{VRBook}. Interaction methods allowing such an acting are called FR interactions. \\

Whereas the CR interactions differ mainly in the accuracy of the selection of an object while grabbing it, the FR methods differ in their usability. All characteristics of the various interaction methods can be traced in their descriptions (compare sections~\ref{sec:TouchGrab} -~\ref{sec:RaycastHMD}).

For a better understanding it should be mentioned, that all interaction methods can be controlled with the \textit{HTC Vive}-controller. Even there are plenty of different possibilities to grab an object, all methods have in common, that the grabbing is caused by pressing the trigger on the \textit{HTC Vive}-controller. The releasing of the object is than triggered by letting it go. Whenever there is a divergent Usability necessary, it is described in the respective section (compare~\ref{sec:ExtendableRay}).

Due to an easier integration into the learning room, as well as the actual supermarker scenes (compare section~\ref{sec:VRLabor}), all methods using a ray (compare sections~\ref{sec:ExtendableRay},~\ref{sec:Raycast} and ~\ref{sec:WandGrab}) are summed up in one script called \textit{AllRaycastMethods.cs}. All other methods have their on script, where the grabbing and releasing is implemented. Also the \textit{Raycast Head Mounted Display}-method, described in section~\ref{sec:RaycastHMD}, is using a ray, it is not included into the script mentioned above. This is caused by remaining problems during the implementation of this method, which lead to an unfinished work. Further explanations on why this method is not available in the \textit{Interaction Lab} can be found in the according section.

The two interaction methods, described in sections~\ref{sec:TouchGrab} or rather~\ref{sec:ProximityGrab}, can be used with snapping or without it. This technique is used to reassign the position and orientation of a grabbed object in hand. By assuming that the middle of the ring of the \textit{HTC Vive}-controller is the new center of the grabbed object, the actual grab could appear more realistic to the user. 

In the following sections all available interaction methods of the \textit{Interaction Lab} are presented. To guarantee a better overview they are sorted by their interaction range. 

\subsubsection{Close Range: Touch Grab} \label{sec:TouchGrab}

\subsubsection{Close Range: Proximity Grab} \label{sec:ProximityGrab}
%ungenaueste Methode

The functionality is provided by the script \textit{\textcolor{red}{ProximityGrab.cs}}. The basic idea is that the object can be grabbed, whenever the object triggers the \textit{BoxCollider} \cite{website:BoxCollider} placed at the end of the \textit{HTC Vive}-controller. In contrast to the \textit{Touch Grab} described in section~\ref{sec:TouchGrab} this collider is bigger than the actual size of the controller. 


\subsubsection{Close Range: Wand Grab} \label{sec:WandGrab}
In contrast to the interaction method described in \ref{sec:ProximityGrab} this method can be used to grab very tiny objects. Thereby it is not needed that the target object is very isolated from other objects. To give the user such an high grade of accuracy a stick is added to the controller like shown on figure \textcolor{red}{PICTURE}. The user can grab an virtual object he touches with the \textit{HTC Vive}-controller by pulling the trigger. To place the object on the target area he simply release the trigger after he moved the object to its destination. \\
%Umsetzung in AllRaycastMethods.cs


\subsubsection{Far Range: Raycast} \label{sec:Raycast}
%Umsetzung in AllRaycastMethods.cs
\subsubsection{Far Range: Extendable Ray} \label{sec:ExtendableRay}
%Umsetzung in AllRaycastMethods.cs
\subsubsection{Far Range: Raycast Head Mounted Display} \label{sec:RaycastHMD}
%Der vollst√§ndigkeithalber..
%konnte nicht integirert werden weil...





\subsection{Self-Teaching} \label{sec:selfteaching}
\todo[inline, color=red]{Anna}

\newpage